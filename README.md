# MarCon
This is the official repository for our ACL2025 (Main Conference) paper **Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models' Uncertainty?**

## Introduction
This paper investigates whether large language models can reliably/consistently express their confidence using epistemic markers instead of numerical values. Our findings indicate that while LLMs' in-distribution marker confidence is relatively stable, its **consistency declines in out-of-distribution scenarios in different perspectives**, raising concerns about the reliability of such markers for confidence estimation.

## Conda Environment
[TBD]

## Code Usage
[TBD]

## Citing this work
[TBD]

# Acknowledgement
This paper investigates whether large language models (LLMs) can reliably express their confidence using epistemic markers (e.g., "fairly certain") instead of numerical values. The findings indicate that while LLMs' in-distribution marker confidence is relatively stable, its consistency declines in out-of-distribution scenarios, raising concerns about the reliability of such markers for confidence estimation.
